{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9a72d95",
   "metadata": {},
   "source": [
    "\n",
    "# House Prices - Advanced Regression Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63285527",
   "metadata": {},
   "source": [
    "In this notebook we will use a dataset provided by **Kaggle** for the competition [House Prices - Advanced Regression Techniques](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques).  \n",
    "\n",
    "First we will explore the data and do some basic EDA, and then we will implement both a Random Forest and a neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0884b870",
   "metadata": {},
   "source": [
    "Before we start we need to import the resources (libraries, modules, etc.) that we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0efa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Normalization, StringLookup, CategoryEncoding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a51658",
   "metadata": {},
   "source": [
    "As the data provided has many features, we will set up **Pandas** to display all columns and rows, making it easier to explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d318d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4484616",
   "metadata": {},
   "source": [
    "## 1. Initial exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd18a772",
   "metadata": {},
   "source": [
    "The data provided by Kaggle has already been separated into train and test datasets, each in a different CSV file.  \n",
    "Both datasets have the same format, the only difference is our target variable **SalePrice** is missing in the test set.\n",
    "Along with the data, a file called data_description.txt is provided which contains a description of each column (and of their values in the categorical ones).\n",
    "\n",
    "We will start by loading the training data and doing some basic exploration to understand what we are dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a491039",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainrawdata_path = '../data/raw/train.csv' # Path to the training dataset\n",
    "traindf = pd.read_csv(trainrawdata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b902480",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e13b49b",
   "metadata": {},
   "source": [
    "We can see that our training dataset has 1460 datapoints, with 79 features (81 columns but one is **Id** and another is the target variable **SalePrice**).  \n",
    "There seems to be missing data in some features, which we will explore later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63a2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bc168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d31d80f",
   "metadata": {},
   "source": [
    "After this first look we see that we have a mixed set of data, some columns are quantitative (numerical) like our target variable **SalePrice** or **LotArea** while many others are qualitative (categorical).  \n",
    "Some of the categorical features are nominal but there are also ordinal variables like **OverallCond** which rates from 1 to 10 the overall condition of the house."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a05bbb6",
   "metadata": {},
   "source": [
    "Lets have an initial look at our target variable **Saleprice**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e26f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55abf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(traindf['SalePrice'], kde=True)\n",
    "plt.title('Distribution of SalePrice')\n",
    "plt.xlabel('SalePrice')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c34c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(np.log1p(traindf['SalePrice']), kde=True)\n",
    "plt.title('Log-Transformed SalePrice')\n",
    "plt.xlabel('Log(SalePrice)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76927b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 1))\n",
    "sns.boxplot(x=traindf['SalePrice'])\n",
    "plt.title('Boxplot of SalePrice')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a4a65b",
   "metadata": {},
   "source": [
    "After an initial look at our target variable **SalePrice** we can see a right-skewed distribution.  \n",
    "This is to be expected as most houses will sell around the same price with the more expensive ones being fewer in number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d756df",
   "metadata": {},
   "source": [
    "## 2. Missing Values Analysis & Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84fd07",
   "metadata": {},
   "source": [
    "### 2.1 Missing values on training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d925b616",
   "metadata": {},
   "source": [
    "Now lets look at which features have missing values and how many each have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1154670",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.isnull().sum().sort_values(ascending=False)[lambda x: x > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f091ac54",
   "metadata": {},
   "source": [
    "\n",
    "As per the data_description.txt file, many of these features use NA as intented value, meaning \"None\".  \n",
    "But there are other variables where that is not the case, like **GarageYrBlt** or **MasVnrArea**.  \n",
    "\n",
    "As there are not that many features, lets explore them manually and deal with them accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf84256a",
   "metadata": {},
   "source": [
    "**PoolQC** is a categorical variable which describes the quality of the pool, NA is not one of the categories but given that there is no category for \"No pool\", those 1453 missing values should mean that those 1453 houses have no pool.  \n",
    "\n",
    "We can confirm this looking at how many houses have 0 pool area and checking if those entries are the same as the ones with **PoolQC** missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb65b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(traindf['PoolArea'] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcf7345",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf[(traindf['PoolArea'] == 0) & (traindf['PoolQC'].isnull())].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c81d6f2",
   "metadata": {},
   "source": [
    "Now lets transform empty values into a string \"None\" to avoid issues with missing values downstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47b8dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['PoolQC'] = traindf['PoolQC'].fillna('None')\n",
    "traindf['PoolQC'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86ad7b8",
   "metadata": {},
   "source": [
    "**MiscFeature** is also a categorical variable with NA as intended value for None, lets compare it with **MiscVal** which represents the value of said feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6afec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(traindf['MiscVal'] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf[(traindf['MiscVal'] == 0) & (traindf['MiscFeature'].isnull())].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e442076",
   "metadata": {},
   "source": [
    "There seems to be 2 instances of **MiscVal** 0 more than the number of entries with **MiscFeature** as NA.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fd7d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf[(traindf['MiscVal'] == 0) & (traindf['MiscFeature'].notna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48867201",
   "metadata": {},
   "source": [
    "As there are only 2 entries, we will drop them and replace the NA values of the rest of **MiscFeature** with \"None\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99b3872",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = traindf.drop(index=traindf[(traindf['MiscVal'] == 0) & (traindf['MiscFeature'].notna())].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c163a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['MiscFeature'] = traindf['MiscFeature'].fillna('None')\n",
    "traindf['MiscFeature'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae23e4b9",
   "metadata": {},
   "source": [
    "Both **Alley** and **Fence** also use NA as None. This time there is no information to crosscheck, so we will assume all NA values are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66e1600",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['Alley'] = traindf['Alley'].fillna('None')\n",
    "traindf['Alley'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366c66f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['Fence'] = traindf['Fence'].fillna('None')\n",
    "traindf['Fence'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0478195",
   "metadata": {},
   "source": [
    "**MasVnrType** is a categorical variable that describes the type of masonry veneer, and **MasVnrArea** is a numerical variable that measures its area in square feet.  \n",
    "For the type there is a None category but with None instead of NA. Lets check its values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a29dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(traindf['MasVnrArea'] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33994664",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['MasVnrArea'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f15250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['MasVnrType'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1a8cf8",
   "metadata": {},
   "source": [
    "There seems to be some type of inconsistency here, as we have 870 missing values on **MasVnrType**, 8 missing values on **MasVnrArea**, and 859 values of 0 area.  \n",
    "We should first check which rows have unexpected values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4722a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf[(traindf['MasVnrArea'] > 0) & (traindf['MasVnrType'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27bf846",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf[(traindf['MasVnrArea'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8bf610",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf[(traindf['MasVnrArea'] == 0) & ~(traindf['MasVnrType'].isnull())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f0b2fe",
   "metadata": {},
   "source": [
    "We can see 4 different cases here:  \n",
    "> 8 entries where both type and area are NA  \n",
    "> 2 entries where type is NA but where the area is 1.0, which would not make sense as that area value is too small  \n",
    "> 3 entries where type is NA but where the area has a reasonable value  \n",
    "> 2 entries where there is a valid type but the area is 0  \n",
    "\n",
    "We are going to drop the entries with both values missing, and the two with 1.0 as area, because they are only 10 entries (<1% of the total).  \n",
    "\n",
    "As for the other two cases, we are going to replace the missing values with the mode of the type from its neighborhood, and with the median of the neighborhood of the area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8901ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = traindf.drop(index=traindf[(traindf['MasVnrType'].isnull()) & (traindf['MasVnrArea'].isnull())].index)\n",
    "traindf = traindf.drop(index=traindf[(traindf['MasVnrArea'] == 1.0)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d495d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boolean mask for those rows where MasVnrType is NaN and MasVnrArea is not 0\n",
    "mask1 = traindf['MasVnrType'].isna() & (traindf['MasVnrArea'] != 0)\n",
    "\n",
    "# Create boolean mask for those rows where MasVnrType has a valid value and MasVnrArea is 0\n",
    "mask2 = ~traindf['MasVnrType'].isna() & (traindf['MasVnrArea'] == 0)\n",
    "\n",
    "# Group by Neighborhood and get the mode of MasVnrType by Neighborhood and the median of MasVnrArea.\n",
    "MasVnrType_mode_Neighborhood = (traindf.groupby('Neighborhood')['MasVnrType'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else 'None'))\n",
    "MasVnrArea_median_Neighborhood = traindf.groupby('Neighborhood')['MasVnrArea'].median()\n",
    "\n",
    "# Map the mode values to the original DataFrame\n",
    "traindf.loc[mask1, 'MasVnrType'] = traindf.loc[mask1, 'Neighborhood'].map(MasVnrType_mode_Neighborhood)\n",
    "traindf.loc[mask2, 'MasVnrArea'] = traindf.loc[mask2, 'Neighborhood'].map(MasVnrArea_median_Neighborhood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6823aa95",
   "metadata": {},
   "source": [
    "Lets check whether all the missing values remaining matches the number of properties without masonry veneer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8be4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traindf['MasVnrType'].isnull().sum())\n",
    "print((traindf['MasVnrArea'] == 0).sum())\n",
    "traindf[(traindf['MasVnrArea'] == 0) & ~(traindf['MasVnrType'].isnull())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085f13a6",
   "metadata": {},
   "source": [
    "We can see there is still an entry with valid veneer type but area 0, this means that the median of that neighborhood is 0.  \n",
    "As it is only one entry, our safest approach is to just drop this one entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0cdd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = traindf.drop(index=traindf[(traindf['MasVnrArea'] == 0) & ~(traindf['MasVnrType'].isnull())].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c517d3",
   "metadata": {},
   "source": [
    "Now we will replace the NA values in type by 'None'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbfcce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['MasVnrType'] = traindf['MasVnrType'].fillna('None')\n",
    "traindf['MasVnrType'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddbe544",
   "metadata": {},
   "source": [
    "**FireplaceQu** has NA as None, and the amount should match the amount of 0 **Fireplaces**.  \n",
    "If so, we will just replace those NA with \"None\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b030ad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(traindf['FireplaceQu'].isnull()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977d3369",
   "metadata": {},
   "outputs": [],
   "source": [
    "(traindf['Fireplaces'] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8784195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf[(traindf['Fireplaces'] == 0) & (traindf['FireplaceQu'].isnull())].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6ca555",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['FireplaceQu'] = traindf['FireplaceQu'].fillna('None')\n",
    "traindf['FireplaceQu'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630f8459",
   "metadata": {},
   "source": [
    "**LotFrontage** shows the linear feet of street connected to the house.  \n",
    "As there is a big number of missing values (~17%), dropping them would not be reasonable.  \n",
    "Instead, we will replace those values by the median of the neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd9a78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boolean mask for those rows where LotFrontage is NA.\n",
    "mask = traindf['LotFrontage'].isna()\n",
    "\n",
    "# Group by Neighborhood and get the mode of LotFrontage by Neighborhood\n",
    "LotFrontage_median_Neighborhood = traindf.groupby('Neighborhood')['LotFrontage'].median()\n",
    "\n",
    "# Map the mode values to the original DataFrame\n",
    "traindf.loc[mask, 'LotFrontage'] = traindf.loc[mask, 'Neighborhood'].map(LotFrontage_median_Neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2be679",
   "metadata": {},
   "outputs": [],
   "source": [
    "(traindf['LotFrontage'].isnull()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1754979",
   "metadata": {},
   "source": [
    "Now we will check the garage related variables.\n",
    "We have 81 missing values on **GarageQual, GarageType, GarageFinish, GarageYrBlt, GarageExposure**.  \n",
    "All those are categorical and have NA as legitimate value for \"no garage\", except **GarageYrBlt** which is numerical (year the garage was built).  \n",
    "\n",
    "Besides those, we can see two more variables related to the garage, **GarageArea** and **GarageCars** which are numerical variables.\n",
    "\n",
    "Now we should check that those 81 missing values on each feature, they all match 81 unique entries, that at the same time should have all of them 0 in both Area and Cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94bc2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(traindf['GarageCars'] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460b1903",
   "metadata": {},
   "outputs": [],
   "source": [
    "(traindf['GarageArea'] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17c95ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf[(traindf['GarageArea'] == 0) & (traindf['GarageCars'] == 0) & (traindf['GarageQual'].isnull()) \n",
    "        & (traindf['GarageType'].isnull()) & (traindf['GarageFinish'].isnull()) \n",
    "        & (traindf['GarageCond'].isnull()) & (traindf['GarageYrBlt'].isnull())].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5b9bcf",
   "metadata": {},
   "source": [
    "After checking this we can safely replace NA values on the categorical variables with \"None\", and for **GarageYrBlt** we will replace with -1 as a placeholder to indicate there is no garage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0007eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n",
    "    traindf[var] = traindf[var].fillna('None')\n",
    "    print(f\"Unique values in {var}: {traindf[var].unique()}\")\n",
    "traindf['GarageYrBlt'] = traindf['GarageYrBlt'].fillna(-1)\n",
    "(traindf['GarageYrBlt'] == -1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e046b4d3",
   "metadata": {},
   "source": [
    "As far as basement related variables, we have 11 in total:\n",
    "> **BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2**, these 5 categorical features use NA as value for \"no basement\", and those are the ones that show missing values.  \n",
    "> **BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF**, these 4 numerical features describe the area in square feet of the different sections of the basement, they have no missing values.  \n",
    "> **BsmtFullBath, BsmtHalfBath**, these 2 numerical features describe the amount of full and half bathrooms that there are in the basement, they have no missing values.  \n",
    "\n",
    "We expect to see that those entries with missing values in all 5 categorical features, should have 0 as value in all the numerical variables.  \n",
    "First we will check that and replace the missing values with \"None\" and then we can focus in the rest of the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc74480",
   "metadata": {},
   "outputs": [],
   "source": [
    "BsmtCatCols = ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']\n",
    "mask = traindf[BsmtCatCols].isnull().all(axis=1)\n",
    "\n",
    "print(\"Basement 1 area: \", \n",
    "      traindf[mask][\"BsmtFinSF1\"].value_counts())\n",
    "\n",
    "print(\"Basement 2 area: \", \n",
    "      traindf[mask][\"BsmtFinSF2\"].value_counts())\n",
    "\n",
    "print(\"Unfinished basement area: \", \n",
    "      traindf[mask][\"BsmtUnfSF\"].value_counts())\n",
    "\n",
    "print(\"Basement total area: \", \n",
    "      traindf[mask][\"TotalBsmtSF\"].value_counts())\n",
    "\n",
    "print(\"Basement full bathrooms: \", \n",
    "      traindf[mask][\"BsmtFullBath\"].value_counts())\n",
    "\n",
    "print(\"Basement half bathrooms: \", \n",
    "      traindf[mask][\"BsmtHalfBath\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfdc10c",
   "metadata": {},
   "source": [
    "With that we can safely replace in those 37 entries the missing value with \"None\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c25deb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.loc[mask, BsmtCatCols] = traindf.loc[mask, BsmtCatCols].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fa2fcb",
   "metadata": {},
   "source": [
    "Lets check what missing values remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13c078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.isnull().sum().sort_values(ascending=False)[lambda x: x > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d9c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf[traindf[\"BsmtExposure\"].isnull() | traindf[\"BsmtFinType2\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6088cc",
   "metadata": {},
   "source": [
    "We can see that there is one entry with **BsmtFinType2** empty even though there is surface area and the other values make sense, and another entry where **BsmtExposure**'s value is missing even though the rest of the values indicate that there is an unfinished basement. Both cases seem to be missing information, not empty on purpose.  \n",
    "\n",
    "Given that it is only 2 entries, we will drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6176b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = traindf.drop(index=traindf[traindf[\"BsmtExposure\"].isnull() | traindf[\"BsmtFinType2\"].isnull()].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9095750",
   "metadata": {},
   "source": [
    "As for the entry with the **Electrical** feature missing, we will drop it too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2beb90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = traindf.drop(index=traindf[traindf[\"Electrical\"].isnull()].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c7d552",
   "metadata": {},
   "source": [
    "Before we proceed lets check all missing values have been dealt with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e90cd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.isnull().sum().sort_values(ascending=False)[lambda x: x > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46972910",
   "metadata": {},
   "source": [
    "An empty list means there are no more missing values in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36aa439",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643a7c55",
   "metadata": {},
   "source": [
    "We have lost in total 16 rows (~1%), but now we have a clean dataset that will not give us problems when we implement any models that cannot deal with missing values natively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6151c565",
   "metadata": {},
   "source": [
    "Lets save the cleaned dataset into a CSV file before proceeding with the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336220c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean_output_path = '../data/processed/train_clean.csv'  # Output file path\n",
    "traindf.to_csv(train_clean_output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3212a1f8",
   "metadata": {},
   "source": [
    "### 2.2 Missing values on test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a050c27",
   "metadata": {},
   "source": [
    "Now we will repeat the same operations with the test dataset provided, but without dropping any rows as we will need to make a prediction from all of them.  \n",
    "\n",
    "We will start by loading the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab3ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtestdata_path = '../data/raw/test.csv' # Path to the test dataset\n",
    "testdf = pd.read_csv(rawtestdata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514050d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf.isnull().sum().sort_values(ascending=False)[lambda x: x > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd6c2d7",
   "metadata": {},
   "source": [
    "We have more features with missing values in the test dataset than in the train set, but most seem to be one or two entries.  \n",
    "\n",
    "As we cannot drop rows on the test set given that we need to make a prediction for all of them, lets first apply carefully the same transformations as with the training set and see what remains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360e8151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NA with 'None' in every missing PoolQC that has PoolArea = 0\n",
    "mask = (testdf[\"PoolArea\"] == 0) & (testdf[\"PoolQC\"].isnull())\n",
    "testdf.loc[mask, \"PoolQC\"] = 'None'\n",
    "\n",
    "# Replace NA with 'None' in every missing MiscFeature that has MiscVal = 0\n",
    "mask = (testdf[\"MiscVal\"] == 0) & (testdf[\"MiscFeature\"].isnull())\n",
    "testdf.loc[mask, \"MiscFeature\"] = 'None'\n",
    "\n",
    "# Replace NA with 'None' in every missing Alley and Fence\n",
    "testdf['Alley'] = testdf['Alley'].fillna('None')\n",
    "testdf['Fence'] = testdf['Fence'].fillna('None')\n",
    "\n",
    "# For those with both MasVnrtype and MasVnrArea missing, we will first replace the area with the median of the neighborhood from the training set\n",
    "mask = testdf['MasVnrType'].isna() & (testdf['MasVnrArea'].isna())\n",
    "testdf.loc[mask, 'MasVnrArea'] = testdf.loc[mask, 'Neighborhood'].map(MasVnrArea_median_Neighborhood)\n",
    "# Then replace the MasVnrType with the mode of the neighborhood from the training set on those rows with a valid MasVnrArea (>0)\n",
    "mask = testdf['MasVnrType'].isna() & (testdf['MasVnrArea'] > 0)\n",
    "testdf.loc[mask, 'MasVnrType'] = testdf.loc[mask, 'Neighborhood'].map(MasVnrType_mode_Neighborhood)\n",
    "# And for those with MasVnrArea = 0 and MasVnrType missing, we will replace the type with 'None'\n",
    "mask = testdf['MasVnrType'].isna() & (testdf['MasVnrArea'] == 0)\n",
    "testdf.loc[mask, \"MasVnrType\"] = 'None'\n",
    "\n",
    "# Replace NA with 'None' in every missing FireplaceQu that has Fireplaces = 0\n",
    "mask = (testdf[\"Fireplaces\"] == 0) & (testdf[\"FireplaceQu\"].isnull())\n",
    "testdf.loc[mask, \"FireplaceQu\"] = 'None'\n",
    "\n",
    "# Replace NA with the median LotFrontage of the neighborhood from the training set\n",
    "mask = testdf['LotFrontage'].isna()\n",
    "testdf.loc[mask, 'LotFrontage'] = testdf.loc[mask, 'Neighborhood'].map(LotFrontage_median_Neighborhood)\n",
    "\n",
    "# Replace NA with 'None' in every missing categorical Garage variables, with -1 in GarageYrBlt and with 0 in GarageArea and GarageCars\n",
    "# But only for those entries where all Garage variables mean there is no garage\n",
    "mask = (\n",
    "    ((testdf['GarageArea'].isnull()) | (testdf['GarageArea'] == 0)) &\n",
    "    ((testdf['GarageCars'].isnull()) | (testdf['GarageCars'] == 0)) &\n",
    "    (testdf['GarageQual'].isnull()) &\n",
    "    (testdf['GarageType'].isnull()) &\n",
    "    (testdf['GarageFinish'].isnull()) &\n",
    "    (testdf['GarageCond'].isnull()) &\n",
    "    ((testdf['GarageYrBlt'].isnull()) | (testdf['GarageYrBlt'] == 0))\n",
    ")\n",
    "\n",
    "for var in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n",
    "    testdf.loc[mask, var] = 'None'\n",
    "testdf.loc[mask, 'GarageYrBlt'] = -1\n",
    "testdf.loc[mask, 'GarageArea'] = 0\n",
    "testdf.loc[mask, 'GarageCars'] = 0\n",
    "\n",
    "\n",
    "\n",
    "# Replace NA with 'None' in every missing categorical Basement variables, and with 0 in the numerical ones\n",
    "# But only for those entries where all Basement variables mean there is no basement\n",
    "mask = (\n",
    "    ((testdf['BsmtFinSF1'].isnull()) | (testdf['BsmtFinSF1'] == 0)) &\n",
    "    ((testdf['BsmtFinSF2'].isnull()) | (testdf['BsmtFinSF2'] == 0)) &\n",
    "    ((testdf['BsmtUnfSF'].isnull()) | (testdf['BsmtUnfSF'] == 0)) &\n",
    "    ((testdf['TotalBsmtSF'].isnull()) | (testdf['TotalBsmtSF'] == 0)) &\n",
    "    ((testdf['BsmtFullBath'].isnull()) | (testdf['BsmtFullBath'] == 0)) &\n",
    "    ((testdf['BsmtHalfBath'].isnull()) | (testdf['BsmtHalfBath'] == 0)) &\n",
    "    (testdf['BsmtQual'].isnull()) &\n",
    "    (testdf['BsmtCond'].isnull()) &\n",
    "    (testdf['BsmtExposure'].isnull()) &\n",
    "    (testdf['BsmtFinType1'].isnull()) &\n",
    "    (testdf['BsmtFinType2'].isnull())\n",
    ")\n",
    "for var in ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']:\n",
    "    testdf.loc[mask, var] = 'None'\n",
    "for var in ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath']:\n",
    "    testdf.loc[mask, var] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88119074",
   "metadata": {},
   "source": [
    "Afther that transformation the missing values remaining are the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e33480",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf.isnull().sum().sort_values(ascending=False)[lambda x: x > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0249bf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf.isnull().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb6f1b6",
   "metadata": {},
   "source": [
    "Most missing values have been cleaned, but there are a few remnants over 22 entries that we will deal with manually.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1425396f",
   "metadata": {},
   "source": [
    "Using the information provided in data_description.txt we will proceed with the following:\n",
    "\n",
    "- **MSZoning** we will replace missing values with the mode by neighborhood from the training set\n",
    "- **PoolQC** we will replace missing values with the mode by neighborhood from the training set (we previously already replaced those with 0 **PoolArea** by \"None\")\n",
    "- **Utilities** we will replace missing values with the mode by neighborhood from the training set\n",
    "- **Functional** we will replace missing values with \"Typ\" (From documentation: Assume typical unless deductions are warranted)\n",
    "- **Exterior1st** we will replace missing values with the mode by neighborhood from the training set\n",
    "- **Exterior2nd** we will replace missing values with the mode by neighborhood from the training set\n",
    "- **KitchenQual** we will replace missing values with the mode by neighborhood from the training set\n",
    "- **MiscFeature** we will replace missing values with \"Other\" category (we previously already replaced those with 0 **MiscVal** by \"None)\n",
    "- **SaleType** we will replace missing values with the mode by neighborhood from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c836ea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = testdf['MSZoning'].isna()\n",
    "MSZoning_mode_Neighborhood = (traindf.groupby('Neighborhood')['MSZoning'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else 'None'))\n",
    "testdf.loc[mask, 'MSZoning'] = testdf.loc[mask, 'Neighborhood'].map(MSZoning_mode_Neighborhood)\n",
    "\n",
    "mask = testdf['PoolQC'].isna()\n",
    "PoolQC_mode_Neighborhood = (traindf.groupby('Neighborhood')['PoolQC'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else 'None'))\n",
    "testdf.loc[mask, 'PoolQC'] = testdf.loc[mask, 'Neighborhood'].map(PoolQC_mode_Neighborhood)\n",
    "\n",
    "mask = testdf['Utilities'].isna()\n",
    "Utilities_mode_Neighborhood = (traindf.groupby('Neighborhood')['Utilities'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else 'None'))\n",
    "testdf.loc[mask, 'Utilities'] = testdf.loc[mask, 'Neighborhood'].map(Utilities_mode_Neighborhood)\n",
    "\n",
    "mask = testdf['Functional'].isna()\n",
    "testdf.loc[mask, 'Functional'] = \"Typ\"\n",
    "\n",
    "mask = testdf['Exterior1st'].isna()\n",
    "Exterior1st_mode_Neighborhood = (traindf.groupby('Neighborhood')['Exterior1st'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else 'None'))\n",
    "testdf.loc[mask, 'Exterior1st'] = testdf.loc[mask, 'Neighborhood'].map(Exterior1st_mode_Neighborhood)\n",
    "\n",
    "mask = testdf['Exterior2nd'].isna()\n",
    "Exterior2nd_mode_Neighborhood = (traindf.groupby('Neighborhood')['Exterior2nd'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else 'None'))\n",
    "testdf.loc[mask, 'Exterior2nd'] = testdf.loc[mask, 'Neighborhood'].map(Exterior2nd_mode_Neighborhood)\n",
    "\n",
    "mask = testdf['KitchenQual'].isna()\n",
    "KitchenQual_mode_Neighborhood = (traindf.groupby('Neighborhood')['KitchenQual'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else 'None'))\n",
    "testdf.loc[mask, 'KitchenQual'] = testdf.loc[mask, 'Neighborhood'].map(KitchenQual_mode_Neighborhood)\n",
    "\n",
    "mask = testdf['MiscFeature'].isna()\n",
    "testdf.loc[mask, 'MiscFeature'] = \"Other\"\n",
    "\n",
    "mask = testdf['SaleType'].isna()\n",
    "SaleType_mode_Neighborhood = (traindf.groupby('Neighborhood')['SaleType'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else 'None'))\n",
    "testdf.loc[mask, 'SaleType'] = testdf.loc[mask, 'Neighborhood'].map(SaleType_mode_Neighborhood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009ac760",
   "metadata": {},
   "source": [
    "We should have left the Basement and Garage related variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f064a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf.isnull().sum().sort_values(ascending=False)[lambda x: x > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa3d118",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf.isnull().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ddaa82",
   "metadata": {},
   "source": [
    "They are only 9 entries, lets explore them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b507f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf[testdf.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff57413",
   "metadata": {},
   "source": [
    "We can see there is one entry where even though there is **GarageType** defined, the rest of the information related to the garage is missing, so we are going to assume there is no garage on the property and the type was a data error.  \n",
    "\n",
    "The rest of the entries show enough information about basement and garage, so we will replace the missing parts using the mode by neighborhood on the categorical variables and the median on the numerical ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2e7459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First lets deal with the row where we are assuming there is no garage\n",
    "row_label = testdf[testdf[\"GarageCars\"].isnull()].index[0]\n",
    "# Now lets change the rest of the garage variables\n",
    "for var in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n",
    "    testdf.loc[row_label, var] = 'None'\n",
    "testdf.loc[row_label, \"GarageArea\"] = 0.0\n",
    "testdf.loc[row_label, \"GarageCars\"] = 0.0\n",
    "testdf.loc[row_label, \"GarageYrBlt\"] = -1\n",
    "\n",
    "# Now for the rest, lets replace the missing values of the categorical variables with the mode of the neighborhood from the training set\n",
    "for var in ['GarageFinish', 'GarageQual', 'GarageCond', 'BsmtExposure', 'BsmtQual', 'BsmtCond']:\n",
    "    mask = testdf[var].isna()\n",
    "    mode = (traindf.groupby('Neighborhood')[var].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else 'None'))\n",
    "    testdf.loc[mask, var] = testdf.loc[mask, 'Neighborhood'].map(mode)\n",
    "\n",
    "# And for GarageYrBlt, the only numerical variable, we will replace it with the median of the neighborhood from the training set\n",
    "GarageYrBlt_median_Neighborhood = traindf.groupby('Neighborhood')['GarageYrBlt'].median()\n",
    "row_label = testdf[testdf[\"GarageYrBlt\"].isnull()].index[0]\n",
    "neighborhood = testdf.loc[row_label, 'Neighborhood']\n",
    "testdf.loc[row_label, 'GarageYrBlt'] = GarageYrBlt_median_Neighborhood[neighborhood]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f42f18",
   "metadata": {},
   "source": [
    "Let's do a final check to make sure all missing values have been dealt with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dcb4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf.isnull().sum().sort_values(ascending=False)[lambda x: x > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cb421d",
   "metadata": {},
   "source": [
    "And now lets save the cleaned test dataset to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba7d2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clean_output_path = '../data/processed/test_clean.csv'  # Output file path\n",
    "testdf.to_csv(test_clean_output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3842157f",
   "metadata": {},
   "source": [
    "## 3. Feature engineering  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc3e8ff",
   "metadata": {},
   "source": [
    "Given the information available, there are a few features that could provide useful information for our prediction task.  \n",
    "\n",
    "We are going to create the following on both sets of data:\n",
    "- **TotalBathrooms**: Including basement ones\n",
    "- **TotalSF**: Both floors plus basement\n",
    "- **FinishedSF**: Total livable area (excluding unfinished basement)\n",
    "- **Has2ndFloor**: Yes/No\n",
    "- **HasBasement**: Yes/No\n",
    "- **HasGarage**: Yes/No\n",
    "- **HasPool**: Yes/No\n",
    "- **HouseAge**: Years from when it was build till sale\n",
    "- **GarageAge**: Years from when it was build till sale\n",
    "- **RemodelAge**: Years from last remodelation till sale\n",
    "- **WasRemodeled**: Yes/No\n",
    "- **QualityIndex**: Ratio expressing overall quality and condition\n",
    "- **LotRatio**: Ratio expressing relative house to land size (area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd914eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf[\"TotalBathrooms\"] = traindf[\"FullBath\"] + (0.5 * traindf[\"HalfBath\"]) + traindf[\"BsmtFullBath\"] + (0.5 * traindf[\"BsmtHalfBath\"])\n",
    "testdf[\"TotalBathrooms\"] = testdf[\"FullBath\"] + (0.5 * testdf[\"HalfBath\"]) + testdf[\"BsmtFullBath\"] + (0.5 * testdf[\"BsmtHalfBath\"])\n",
    "\n",
    "traindf[\"TotalSF\"] = traindf[\"TotalBsmtSF\"] + traindf[\"1stFlrSF\"] + traindf[\"2ndFlrSF\"]\n",
    "testdf[\"TotalSF\"] = testdf[\"TotalBsmtSF\"] + testdf[\"1stFlrSF\"] + testdf[\"2ndFlrSF\"]\n",
    "\n",
    "traindf[\"FinishedSF\"] = traindf[\"BsmtFinSF1\"] + traindf[\"BsmtFinSF2\"] + traindf[\"1stFlrSF\"] + traindf[\"2ndFlrSF\"]\n",
    "testdf[\"FinishedSF\"] = testdf[\"BsmtFinSF1\"] + testdf[\"BsmtFinSF2\"] + testdf[\"1stFlrSF\"] + testdf[\"2ndFlrSF\"]\n",
    "\n",
    "traindf[\"Has2ndFloor\"] = (traindf[\"2ndFlrSF\"] > 0).astype(int)\n",
    "testdf[\"Has2ndFloor\"] = (testdf[\"2ndFlrSF\"] > 0).astype(int)\n",
    "\n",
    "traindf[\"HasBasement\"] = (traindf[\"TotalBsmtSF\"] > 0).astype(int)\n",
    "testdf[\"HasBasement\"] = (testdf[\"TotalBsmtSF\"] > 0).astype(int)\n",
    "\n",
    "traindf[\"HasGarage\"] = (traindf[\"GarageArea\"] > 0).astype(int)\n",
    "testdf[\"HasGarage\"] = (testdf[\"GarageArea\"] > 0).astype(int)\n",
    "\n",
    "traindf[\"HasPool\"] = (traindf[\"PoolArea\"] > 0).astype(int)\n",
    "testdf[\"HasPool\"] = (testdf[\"PoolArea\"] > 0).astype(int)\n",
    "\n",
    "traindf[\"HouseAge\"] = traindf[\"YrSold\"] - traindf[\"YearBuilt\"]\n",
    "testdf[\"HouseAge\"] = testdf[\"YrSold\"] - testdf[\"YearBuilt\"]\n",
    "\n",
    "traindf[\"GarageAge\"] = traindf[\"YrSold\"] - traindf[\"GarageYrBlt\"]\n",
    "testdf[\"GarageAge\"] = testdf[\"YrSold\"] - testdf[\"GarageYrBlt\"]\n",
    "\n",
    "traindf[\"RemodelAge\"] = traindf[\"YrSold\"] - traindf[\"YearRemodAdd\"]\n",
    "testdf[\"RemodelAge\"] = testdf[\"YrSold\"] - testdf[\"YearRemodAdd\"]\n",
    "\n",
    "traindf[\"WasRemodel\"] = (traindf[\"YearRemodAdd\"] != traindf[\"YearBuilt\"]).astype(int)\n",
    "testdf[\"WasRemodel\"] = (testdf[\"YearRemodAdd\"] != testdf[\"YearBuilt\"]).astype(int)\n",
    "\n",
    "traindf[\"QualityIndex\"] = traindf[\"OverallQual\"] * traindf[\"OverallCond\"]\n",
    "testdf[\"QualityIndex\"] = testdf[\"OverallQual\"] * testdf[\"OverallCond\"]\n",
    "\n",
    "traindf[\"LotRatio\"] = traindf[\"GrLivArea\"] / traindf[\"LotArea\"]\n",
    "testdf[\"LotRatio\"] = testdf[\"GrLivArea\"] / testdf[\"LotArea\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b898fce",
   "metadata": {},
   "source": [
    "Besides this, we will drop the **Id** column in both datasets, as it offers no useful information for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf1169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.drop('Id', axis=1, inplace=True)\n",
    "testdf.drop('Id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9820606a",
   "metadata": {},
   "source": [
    "And lets save both engineered datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0379ab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eng_output_path = '../data/processed/train_engineered.csv'  # Output file path\n",
    "traindf.to_csv(train_eng_output_path, index=False)\n",
    "\n",
    "test_eng_output_path = '../data/processed/test_engineered.csv'  # Output file path\n",
    "testdf.to_csv(test_eng_output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6ccb13",
   "metadata": {},
   "source": [
    "## 4. Preprocessing for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd635f6",
   "metadata": {},
   "source": [
    "We are going to build a series of different models, and the preprocessing necessary differs between them.  \n",
    "As such, in this section we will only apply those transformations that are common to all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e910313",
   "metadata": {},
   "source": [
    "### 4.1 Log-transform target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f937352b",
   "metadata": {},
   "source": [
    "Let's transform our target variable **SalePrice** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fce5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf[\"SalePrice\"] = np.log1p(traindf[\"SalePrice\"]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663271fd",
   "metadata": {},
   "source": [
    "### 4.2 Sanitize variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239f927a",
   "metadata": {},
   "source": [
    "To avoid mixed data types problems, specially with the neural networks models, we will sanitize the data by making sure all data has the following format:  \n",
    "- Numerical variables: float32\n",
    "- Categorical variables: String"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05f6bac",
   "metadata": {},
   "source": [
    "First we need separate into two lists, the categorical and numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f480850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['MSSubClass', 'MSZoning',  'Street', 'Alley',\n",
    "       'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n",
    "       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n",
    "       'OverallQual', 'OverallCond',  'RoofStyle',\n",
    "       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
    "       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
    "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC',\n",
    "       'CentralAir', 'Electrical', 'KitchenQual', \n",
    "       'Functional', 'FireplaceQu', 'GarageType',\n",
    "       'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "       'PavedDrive',  'PoolQC', 'Fence', 'MiscFeature', 'MoSold',\n",
    "       'SaleType', 'SaleCondition',  'Has2ndFloor', 'HasBasement', 'HasGarage',\n",
    "       'HasPool', 'WasRemodel']\n",
    "\n",
    "num_features = ['LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea',\n",
    "        'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', \n",
    "        'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
    "        'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt',\n",
    "        'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
    "        'ScreenPorch', 'PoolArea', 'MiscVal',  'YrSold', 'TotalBathrooms',\n",
    "        'TotalSF', 'FinishedSF', 'HouseAge', 'GarageAge', 'RemodelAge', 'QualityIndex', 'LotRatio']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81166ba5",
   "metadata": {},
   "source": [
    "And now we will loop over the features changing types where necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcd2eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in cat_features:\n",
    "    traindf[cat] = traindf[cat].astype(str)\n",
    "    testdf[cat] = testdf[cat].astype(str)\n",
    "\n",
    "for num in num_features:\n",
    "    traindf[num] = traindf[num].astype(np.float32)\n",
    "    testdf[num] = testdf[num].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5965a3a6",
   "metadata": {},
   "source": [
    "### 4.3 Data split for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55802a08",
   "metadata": {},
   "source": [
    "Our training dataset is relatively small, and the test set has already been split beforehand.  \n",
    "\n",
    "As such, we will split our training set with a 70/30 split for validation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0835ac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = traindf[\"SalePrice\"]\n",
    "X = traindf.drop(\"SalePrice\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eed75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.3, random_state=33)\n",
    "X_dev, X_hold, Y_dev, Y_hold = train_test_split(X_temp, Y_temp, test_size=1/3, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329a146d",
   "metadata": {},
   "source": [
    "## 5. Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71213709",
   "metadata": {},
   "source": [
    "We will use Scikit-Learn to build a simple linear model.  \n",
    "\n",
    "In this case we will use Ridge Regression instead of linear regression due to the high number of features (the regularization could help avoid overfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fd401c",
   "metadata": {},
   "source": [
    "First we will define the preprocessor that will encode the categorical variables using one-hot encoding.  \n",
    "The numerical variables will not be scaled or normalized as it is not necessary for this model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f089e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features),\n",
    "        # numerical columns are passed through unchanged\n",
    "        ('num', 'passthrough', num_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757a5830",
   "metadata": {},
   "source": [
    "We will build the model, and fit it to our training data.  \n",
    "Because this is just a baseline model used for comparison, we will leave the alpha parameter as its default value (1.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5fd54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_model = Pipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", Ridge(alpha=1.0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb4b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "Ridge_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cd6cb5",
   "metadata": {},
   "source": [
    "Now lets evaluate the model on our dev set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7135fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on dev set\n",
    "Y_pred = Ridge_model.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a594b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_rmse_log = root_mean_squared_error(Y_dev, Y_pred)\n",
    "Ridge_rmse = root_mean_squared_error(np.expm1(Y_dev), np.expm1(Y_pred))\n",
    "print(f\"Ridge RMSE (log scale): {Ridge_rmse_log:.4f}\")\n",
    "print(f\"Ridge RMSE (original scale): {np.expm1(Ridge_rmse_log):.4f}\")\n",
    "print(f\"Random Forest RMSE (dollars): {Ridge_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae16d0f6",
   "metadata": {},
   "source": [
    "And also on our holdout set for comparison purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e1458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on hold set\n",
    "Y_pred = Ridge_model.predict(X_hold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aed210",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_rmse_log = root_mean_squared_error(Y_hold, Y_pred)\n",
    "Ridge_rmse = root_mean_squared_error(np.expm1(Y_hold), np.expm1(Y_pred))\n",
    "print(f\"Ridge RMSE (log scale): {Ridge_rmse_log:.4f}\")\n",
    "print(f\"Ridge RMSE (original scale): {np.expm1(Ridge_rmse_log):.4f}\")\n",
    "print(f\"Random Forest RMSE (dollars): {Ridge_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c764ac",
   "metadata": {},
   "source": [
    "## 6. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58e62e5",
   "metadata": {},
   "source": [
    "We will use TensorFLow Decision Forests to build our Random Forest model.  \n",
    "\n",
    "TFDF can handle internally the encoding of categorical features, and as such we will be using the cleaned and engineered datasets directly with no preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf205b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = tfdf.keras.RandomForestModel(\n",
    "    task=tfdf.keras.Task.REGRESSION,        # Define the task (Regression)\n",
    "    num_trees=300,                          # Number of trees in the forest\n",
    "    max_depth=10,                           # Maximum depth of trees\n",
    "    min_examples=5,                         # Minimum number of examples per leaf node\n",
    "    categorical_algorithm=\"CART\",           # Algorithm for handling categorical features\n",
    "    compute_oob_variable_importances=True,  # Compute out-of-bag variable importances\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e427ecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model.fit(tfdf.keras.pd_dataframe_to_tf_dataset(\n",
    "    pd.concat([X_train, Y_train], axis=1), \n",
    "    task=tfdf.keras.Task.REGRESSION, label=\"SalePrice\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03891fb",
   "metadata": {},
   "source": [
    "Lets check the out-of-bag performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a537f627",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_inspector = RF_model.make_inspector()\n",
    "print(RF_inspector.evaluation())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301b5e2f",
   "metadata": {},
   "source": [
    "And finally lets make the predictions with the dev set and evaluate how our model performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a753b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = RF_model.predict(tfdf.keras.pd_dataframe_to_tf_dataset(X_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f5b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RF_rmse_log = root_mean_squared_error(Y_dev, Y_pred)\n",
    "RF_rmse = root_mean_squared_error(np.expm1(Y_dev), np.expm1(Y_pred))\n",
    "\n",
    "print(f\"Random Forest RMSE (log scale): {RF_rmse_log:.4f}\")\n",
    "print(f\"Random Forest RMSE (original scale): {np.expm1(RF_rmse_log):.4f}\")\n",
    "print(f\"Random Forest RMSE (dollars): {RF_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7f8164",
   "metadata": {},
   "source": [
    "There is a substantial improvement already over our baseline model:  \n",
    "- Ridge Holdout RMSE (log scale): 0.1641\n",
    "- RandomForest Holdout RMSE (log scale): 0.1383  \n",
    "\n",
    "But let's finetune it and see if it can be improved further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5e6885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rf_model(num_trees, max_depth, min_examples):\n",
    "    RF_model = tfdf.keras.RandomForestModel(\n",
    "        task=tfdf.keras.Task.REGRESSION,             # Define the task (Regression)\n",
    "        num_trees=num_trees,                         # Number of trees in the forest\n",
    "        max_depth=max_depth,                         # Maximum depth of trees\n",
    "        min_examples=min_examples,                   # Minimum number of examples per leaf node\n",
    "        categorical_algorithm=\"CART\",\n",
    "        compute_oob_variable_importances=False,      # Compute out-of-bag variable importances\n",
    "    )\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    RF_model.fit(tfdf.keras.pd_dataframe_to_tf_dataset(\n",
    "        pd.concat([X_train, Y_train], axis=1), \n",
    "        task=tfdf.keras.Task.REGRESSION, label=\"SalePrice\"), verbose=0)\n",
    "\n",
    "    # Predict on dev set\n",
    "    Y_pred = RF_model.predict(tfdf.keras.pd_dataframe_to_tf_dataset(X_dev))\n",
    "    rmse = root_mean_squared_error(Y_dev, Y_pred)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ff30cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_tuning = []\n",
    "\n",
    "for trees in [100, 300, 500]:\n",
    "    for depth in [8, 10, 12]:\n",
    "        for minex in [2, 5, 10]:\n",
    "            # Evaluate model and get RMSE\n",
    "            rmse = evaluate_rf_model(trees, depth, minex)\n",
    "            \n",
    "            # Append the results to the list\n",
    "            RF_tuning.append({\n",
    "                \"num_trees\": trees,\n",
    "                \"max_depth\": depth,\n",
    "                \"min_examples\": minex,\n",
    "                \"rmse\": rmse\n",
    "            })\n",
    "\n",
    "RF_tuning_df = pd.DataFrame(RF_tuning)\n",
    "RF_tuning_df = RF_tuning_df.sort_values(by=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2afd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RF_tuning_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc5237b",
   "metadata": {},
   "source": [
    "Lets now fit the best model and evaluate it against the hold out sample to check if overfit our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34324e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = tfdf.keras.RandomForestModel(\n",
    "    task=tfdf.keras.Task.REGRESSION,        # Define the task (Regression)\n",
    "    num_trees=500,                          # Number of trees in the forest\n",
    "    max_depth=12,                           # Maximum depth of trees\n",
    "    min_examples=5,                         # Minimum number of examples per leaf node\n",
    "    categorical_algorithm=\"CART\",           # Algorithm for handling categorical features\n",
    "    compute_oob_variable_importances=True,  # Compute out-of-bag variable importances\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31287c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model.fit(tfdf.keras.pd_dataframe_to_tf_dataset(\n",
    "    pd.concat([X_train, Y_train], axis=1), \n",
    "    task=tfdf.keras.Task.REGRESSION, label=\"SalePrice\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aedee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_inspector = RF_model.make_inspector()\n",
    "print(RF_inspector.evaluation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cc0534",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = RF_model.predict(tfdf.keras.pd_dataframe_to_tf_dataset(X_hold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ec8a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_rmse_log = root_mean_squared_error(Y_hold, Y_pred)\n",
    "RF_rmse = root_mean_squared_error(np.expm1(Y_hold), np.expm1(Y_pred))\n",
    "\n",
    "print(f\"Random Forest RMSE (log scale): {RF_rmse_log:.4f}\")\n",
    "print(f\"Random Forest RMSE (original scale): {np.expm1(RF_rmse_log):.4f}\")\n",
    "print(f\"Random Forest RMSE (dollars): {RF_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35118afe",
   "metadata": {},
   "source": [
    "Performance has not worsened (it got even better but that is probably just due to the small holdout sample)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59b17f5",
   "metadata": {},
   "source": [
    "## 7. MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480312b6",
   "metadata": {},
   "source": [
    "We will build an MLP model with preprocessing.  \n",
    "\n",
    "First the model will normalize all numerical features, and it will encode the categorical ones.  \n",
    "\n",
    "After preprocessing the input it will then use 2 fully connected layer, with 128 and 64 hidden units, and with 'Relu' as activation function.  \n",
    "\n",
    "As output layer given that this is a regression task, it will have a fully connected layer with one unit and no activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58a3d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "# This will create a dictionary which contains an input layer per feature, to help us preprocess them individually\n",
    "inputs = {}\n",
    "for name in num_features + cat_features:\n",
    "    inputs[name] = Input(shape=(1,), name=name, dtype='float32' if name in num_features else 'string')\n",
    "\n",
    "# Preprocessing for numerical\n",
    "norm_layers = {}\n",
    "for feature in num_features:\n",
    "    norm = Normalization() # Create a Normalization layer\n",
    "    norm.adapt(X_train[feature].values)  # Gets the mean and variance of the training data\n",
    "    norm_layers[feature] = norm(inputs[feature]) # Apply normalization to the input feature\n",
    "\n",
    "# Preprocessing for categorical\n",
    "cat_layers = {}\n",
    "for feature in cat_features:\n",
    "    lookup = StringLookup(output_mode='int') # Layer to map strings to integers\n",
    "    lookup.adapt(X_train[feature].values) # Learns all unique values (categories) of the feature to map them to integers\n",
    "    \n",
    "    vocab_size = lookup.vocabulary_size() # Number of unique values (categories) in the feature + 1 for the UNK token\n",
    "    encoding = CategoryEncoding(output_mode='one_hot', num_tokens=vocab_size) # Convert the integer encoded feature to one-hot encoding\n",
    "    \n",
    "    int_encoded = lookup(inputs[feature]) # Apply the lookup layer to the features\n",
    "    one_hot_encoded = encoding(int_encoded) # Apply the encoding layer to the integer encoded feature\n",
    "    cat_layers[feature] = one_hot_encoded # Store the one-hot encoded tensor to the dict\n",
    "\n",
    "# Combine all features\n",
    "all_features = list(norm_layers.values()) + list(cat_layers.values())\n",
    "x = Concatenate()(all_features)\n",
    "\n",
    "# MLP\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6b6950",
   "metadata": {},
   "source": [
    "Now let's configure the model to use Adam as optimization algorithm, using Mean Squared Error as loss function and we will use RMSE as metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0241d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=[RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cf019f",
   "metadata": {},
   "source": [
    "We need to transform our training data to the format TF expects (dict of column name - array of values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd1d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_inputs = {\n",
    "    name: X_train[name].astype(str).values if name in cat_features else X_train[name].values\n",
    "    for name in num_features + cat_features\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17ea329",
   "metadata": {},
   "source": [
    "Anf finally lets train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5531b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_inputs, Y_train.values, epochs=20, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38963d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_inputs = {name: X_dev[name].values for name in num_features + cat_features}\n",
    "loss, rmse = model.evaluate(dev_inputs, Y_dev.values)\n",
    "print(\"Test RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958acbba",
   "metadata": {},
   "source": [
    "(to be done next)\n",
    "(enconding, scaling, normalizing)\n",
    "## 8. TabNet model\n",
    "## 9. Models comparison\n",
    "## 10. Chosen model test prediction\n",
    "and inverse transformation of predictions np.expm1()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
